---
title: "p8105_hw5_xw3106"
author: Xinyu Wang(xw3106)
output: github_document
---

```{r}
library(tidyverse)
library(broom)
```

# Problem 1
```{r}
# Function: Generate n birthdays and check if duplicates exist
has_dup_birthday <- function(n, days = 365L) {
  bdays <- sample.int(days, size = n, replace = TRUE)
  
  any(duplicated(bdays))
}
```

```{r}
set.seed(8105)

n_grid <- 2:50
B <- 10000

birthday_sim_results <- map_df(n_grid, function(n) {
  
  sims <- replicate(B, has_dup_birthday(n))
  
  tibble(
    n = n,
    prob_dup = mean(sims)
  )
})
```

```{r}
# Visualization: Probability that at least two people share a birthday
ggplot(birthday_sim_results, aes(x = n, y = prob_dup)) +
  geom_line(color = "black") +
  geom_point(size = 1.4) +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1), limits = c(0, 1)) +
  labs(
    title = "Birthday Paradox Simulation (10,000 trials per n)",
    x = "Group size (n)",
    y = "Pr(at least one shared birthday)"
  ) +
  theme_minimal(base_size = 12)
```

# Problem 2
```{r}
# Function: simulate dataset, return estimate and p-value
sim_t_test = function(mu, n = 30, sigma = 5) {
  
  x = rnorm(n, mean = mu, sd = sigma)
  
  test = t.test(x, mu = 0)
  
  # extract mean estimate and p-value
  tibble(
    mu_hat  = mean(x),
    p_value = broom::tidy(test)$p.value,
    mu_true = mu
  )
}

## Run simulation for mu = 0:6 with 5000 duplicates
set.seed(8105)

sim_results =
  map_df(0:6, function(mu) {
    replicate(5000, sim_t_test(mu), simplify = FALSE) |> bind_rows()
  })
```

```{r}
## Summarize simulation results
summary_df =
  sim_results |>
  group_by(mu_true) |>
  summarize(
    power= mean(p_value < 0.05),
    mean_est_all= mean(mu_hat),
    mean_est_rej= mean(mu_hat[p_value < 0.05])
  )

summary_df
```

```{r}
summary_df |>
  ggplot(aes(x = mu_true, y = power)) +
  geom_line() +
  geom_point() +
  labs(
    x = "True mean (μ)",
    y = "Power (Pr(reject H₀))",
    title = "Power of one-sample t-test"
  ) +
  theme_bw(base_size = 12)
```

```{r}
summary_df |>
  pivot_longer(cols = c(mean_est_all, mean_est_rej),
               names_to = "type", values_to = "mean_est") |>
  mutate(type = recode(type,
                       mean_est_all = "mean_est",
                       mean_est_rej = "mean_est_reject]")) |>
  ggplot(aes(x = mu_true, y = mean_est, color = type)) +
  geom_line() +
  geom_point() +
  labs(
    x = "True mean (μ)",
    y = "Average estimate (μ̂)",
    title = "Bias in mean estimates across simulations"
  ) +
  theme_bw(base_size = 12)
```

# Problem 3
```{r}
# Load data
homicide_df =
  read_csv("data/homicide-data.csv")
homicide_df |> 
  glimpse()
```

```{r}
# Create city_state and summarize
city_summary =
  homicide_df |>
  mutate(city_state = str_c(city, ", ", state)) |>
  group_by(city_state) |>
  summarize(
    total = n(),
    unsolved = sum(disposition %in% c("Closed without arrest", "Open/No arrest"))
  )
```

```{r}
# test for Baltimore, MD
baltimore =
  city_summary |>
  filter(city_state == "Baltimore, MD")

baltimore_test =
  prop.test(baltimore$unsolved, baltimore$total)

baltimore_tidy =
  tidy(baltimore_test) |>
  select(estimate, conf.low, conf.high)

baltimore_tidy
```

```{r}
# run prop test for all cities
city_results =
  city_summary |>
  mutate(
    test = map2(unsolved, total, ~prop.test(.x,.y)),
    tidy = map(test, tidy)
  ) |>
  unnest(tidy) |>
  select(city_state, estimate, conf.low, conf.high) |>
  arrange(desc(estimate))
```

```{r}
## Visualization
city_results |>
  mutate(city_state = fct_reorder(city_state, estimate)) |>
  ggplot(aes(x = estimate, y = city_state)) +
  geom_point() +
  geom_errorbar(aes(xmin = conf.low, xmax = conf.high), width = 0.3) +
  labs(
    x = "Estimated proportion of unsolved homicides",
    y = "City",
    title = "Proportion of unsolved homicides by city with 95% interval"
  ) +
  theme_bw(base_size = 12)
```

